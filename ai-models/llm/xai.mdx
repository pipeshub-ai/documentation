---
title: x.ai Grok
description: "Configure PipesHub Workplace AI to use different x.ai Grok models"
---

# x.ai Grok Configuration

![x.ai Grok Configuration Interface](/images/ai-models/xAI_LLMConfig.png)

*The x.ai Grok configuration screen in PipesHub where you'll enter your API Key and Model Name*

PipesHub allows you to integrate with x.ai to enable sophisticated AI features in your workspace, accessing Grok's powerful large language models optimized for high-performance agentic tool calling.

## Required Fields

### API Key *

The API Key is required to authenticate your requests to x.ai services.

**How to obtain an API Key:**
1. Log in to the [x.ai Console](https://console.x.ai/)
2. Navigate to the API Keys section
3. Click on "Create new key" or use an existing key
4. Copy the generated API key

**Security Note:** Your API key should be kept secure and never shared publicly. PipesHub securely stores your API key and uses it only for authenticating requests to x.ai services.

### Model Name *

The Model Name field defines which x.ai Grok model you want to use with PipesHub.

**Available x.ai Grok models:**
- `grok-4-1-fast-reasoning` - **Grok 4.1 Fast (Reasoning)**: A frontier multimodal model optimized specifically for high-performance agentic tool calling with advanced reasoning capabilities.
- `grok-4-1-fast-non-reasoning` - **Grok 4.1 Fast (Non-Reasoning)**: A frontier multimodal model optimized specifically for high-performance agentic tool calling without reasoning overhead.

**How to choose a model:**
- For tasks requiring complex reasoning and logical inference, select `grok-4-1-fast-reasoning`
- For faster responses and efficient tool calling without reasoning overhead, select `grok-4-1-fast-non-reasoning`
- Check x.ai's [model documentation](https://docs.x.ai/docs) for the most up-to-date options

## Optional Fields

### Context Length

Specify the maximum context window for your model. x.ai Grok models typically support large context windows for handling extensive conversations and documents.

**Context length examples:**
- Grok 4.1 Fast models: Check x.ai documentation for specific context window limits

### Multimodal Support

x.ai Grok models support multimodal capabilities, enabling both text and image processing. Enable this option if you want to use image understanding features in your application.

### Reasoning

Enable this option if you're using the `grok-4-1-fast-reasoning` model. This allows for advanced reasoning capabilities and complex problem-solving. Note that the non-reasoning variant is optimized for speed without this overhead.

## Configuration Steps

As shown in the image above:

1. Select "x.ai" as your Provider from the dropdown
2. Enter your x.ai API Key in the designated field (marked with *)
3. Specify your desired Model Name (marked with *)
4. (Optional) Configure the Context Length for your use case
5. (Optional) Enable Multimodal support if needed
6. (Optional) Enable Reasoning if using the reasoning model variant
7. Click "Add Model" to complete setup

> Both the API Key and Model Name are required fields to successfully configure x.ai Grok 
integration. You must complete these fields to proceed with the setup.


## Usage Considerations

- API usage will count against your x.ai API quota and billing
- Different models have different pricing - check x.ai's pricing page for details
- Model capabilities vary - reasoning models provide deeper analysis but may have higher latency
- x.ai Grok provides:
  - High-performance agentic tool calling capabilities
  - Advanced reasoning for complex problem-solving (reasoning variant)
  - Multimodal understanding (text and images)
  - Optimized for fast responses and efficient workflows
  - Frontier-class model performance

## Troubleshooting

- If you encounter authentication errors, verify your API key is correct and has not expired
- Ensure your x.ai account has billing set up if you're using paid service tiers
- Check that the model name is spelled correctly and available
- Verify that your API key has access to the specific model you've selected
- If you're experiencing rate limits, check your API usage in the x.ai Console dashboard
- For multimodal features, ensure your model supports image inputs
- If using reasoning features, ensure you've selected the `grok-4-1-fast-reasoning` model

For additional support, refer to the [x.ai documentation](https://docs.x.ai/) or contact PipesHub support.
